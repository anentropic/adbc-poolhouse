---
phase: 08-review-and-improve-docs
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - src/adbc_poolhouse/_pool_factory.py
  - src/adbc_poolhouse/__init__.py
autonomous: true
requirements: []

must_haves:
  truths:
    - "from adbc_poolhouse import close_pool, managed_pool succeeds"
    - "close_pool(pool) disposes pool and closes ADBC source in one call"
    - "managed_pool(config) as pool creates pool on enter and closes it on exit"
    - "close_pool and managed_pool appear in __all__"
  artifacts:
    - path: "src/adbc_poolhouse/_pool_factory.py"
      provides: "close_pool() and managed_pool() implementations"
      contains: "def close_pool"
    - path: "src/adbc_poolhouse/__init__.py"
      provides: "Public re-exports for close_pool and managed_pool"
      contains: "close_pool"
  key_links:
    - from: "src/adbc_poolhouse/__init__.py"
      to: "src/adbc_poolhouse/_pool_factory.py"
      via: "from adbc_poolhouse._pool_factory import close_pool, managed_pool"
      pattern: "close_pool.*managed_pool"
    - from: "src/adbc_poolhouse/_pool_factory.py"
      to: "pool._adbc_source"
      via: "close_pool calls pool.dispose() then pool._adbc_source.close()"
      pattern: "_adbc_source\\.close"
---

<objective>
Add close_pool() and managed_pool() as public API to replace the two-step
pool.dispose() + pool._adbc_source.close() pattern.

Purpose: The existing dispose pattern exposes a private attribute (_adbc_source)
in user-facing documentation. These two new functions encapsulate the correct
teardown sequence behind a clean public interface.

Output: Two new exported symbols (close_pool, managed_pool) in _pool_factory.py
and re-exported from __init__.py.
</objective>

<execution_context>
@/Users/paul/.claude/get-shit-done/workflows/execute-plan.md
@/Users/paul/.claude/get-shit-done/templates/summary.md
@.claude/skills/adbc-poolhouse-docs-author/SKILL.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/adbc_poolhouse/_pool_factory.py
@src/adbc_poolhouse/__init__.py

<interfaces>
<!-- Existing _pool_factory.py signature that new functions must complement -->

From src/adbc_poolhouse/_pool_factory.py:
```python
def create_pool(
    config: WarehouseConfig,
    *,
    pool_size: int = 5,
    max_overflow: int = 3,
    timeout: int = 30,
    recycle: int = 3600,
    pre_ping: bool = False,
) -> sqlalchemy.pool.QueuePool:
    ...
    pool._adbc_source = source  # type: ignore[attr-defined]
    ...
    return pool
```

From src/adbc_poolhouse/__init__.py:
```python
from adbc_poolhouse._pool_factory import create_pool

__all__ = [
    "ConfigurationError",
    "PoolhouseError",
    "WarehouseConfig",
    "BaseWarehouseConfig",
    "BigQueryConfig",
    "DatabricksConfig",
    "DuckDBConfig",
    "FlightSQLConfig",
    "MSSQLConfig",
    "PostgreSQLConfig",
    "RedshiftConfig",
    "SnowflakeConfig",
    "TrinoConfig",
    "create_pool",
]
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement close_pool and managed_pool in _pool_factory.py</name>
  <files>src/adbc_poolhouse/_pool_factory.py</files>
  <action>
Add two new public functions after the existing create_pool function. Use
`collections.abc.Iterator` (not `typing.Iterator`) — the codebase uses
`from __future__ import annotations` throughout.

`close_pool(pool)` — synchronous dispose helper:

```python
def close_pool(pool: sqlalchemy.pool.QueuePool) -> None:
    """Dispose a pool and close its underlying ADBC source connection.

    Replaces the two-step pattern ``pool.dispose()`` followed by
    ``pool._adbc_source.close()``. Always call this instead of calling
    ``pool.dispose()`` directly to avoid leaving the ADBC source connection open.

    Args:
        pool: A pool returned by :func:`create_pool`.

    Example:
        from adbc_poolhouse import DuckDBConfig, create_pool, close_pool

        pool = create_pool(DuckDBConfig(database='/tmp/wh.db'))
        # ... use pool ...
        close_pool(pool)
    """
    pool.dispose()
    pool._adbc_source.close()  # type: ignore[attr-defined]
```

`managed_pool(config, ...)` — context manager with explicit kwargs matching
create_pool's signature exactly (basedpyright strict mode rejects untyped **kwargs
forwarding — spell out all five kwargs explicitly):

```python
@contextlib.contextmanager
def managed_pool(
    config: WarehouseConfig,
    *,
    pool_size: int = 5,
    max_overflow: int = 3,
    timeout: int = 30,
    recycle: int = 3600,
    pre_ping: bool = False,
) -> collections.abc.Iterator[sqlalchemy.pool.QueuePool]:
    """Context manager that creates a pool and closes it on exit.

    The pool is created when the ``with`` block is entered and closed
    (via :func:`close_pool`) when the block exits, whether it exits normally
    or raises an exception.

    Args:
        config: A warehouse config model instance (e.g. ``DuckDBConfig``).
        pool_size: Number of connections to keep in the pool. Default: 5.
        max_overflow: Extra connections allowed above pool_size. Default: 3.
        timeout: Seconds to wait for a connection before raising. Default: 30.
        recycle: Seconds before a connection is recycled. Default: 3600.
        pre_ping: Whether to ping connections before checkout. Default: False.

    Yields:
        A configured ``sqlalchemy.pool.QueuePool``.

    Example:
        from adbc_poolhouse import DuckDBConfig, managed_pool

        with managed_pool(DuckDBConfig(database='/tmp/wh.db')) as pool:
            with pool.connect() as conn:
                cursor = conn.cursor()
                cursor.execute('SELECT 1')
    """
    pool = create_pool(
        config,
        pool_size=pool_size,
        max_overflow=max_overflow,
        timeout=timeout,
        recycle=recycle,
        pre_ping=pre_ping,
    )
    try:
        yield pool
    finally:
        close_pool(pool)
```

Add `import collections.abc` to the existing imports section. The file already
imports `contextlib` — no need to add it again.

Also update the `create_pool` docstring: replace the disposal instructions that
reference `pool._adbc_source.close()` with a reference to `close_pool(pool)`::

    To shut down cleanly, call :func:`close_pool`::

        close_pool(pool)

Remove: "Callers must close it after ``pool.dispose()``:: ..."
  </action>
  <verify>
    <automated>cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && uv run python -c "from adbc_poolhouse._pool_factory import close_pool, managed_pool; print('OK')"</automated>
  </verify>
  <done>close_pool and managed_pool importable from _pool_factory; create_pool docstring updated to reference close_pool</done>
</task>

<task type="auto">
  <name>Task 2: Export close_pool and managed_pool from __init__.py</name>
  <files>src/adbc_poolhouse/__init__.py</files>
  <action>
Add close_pool and managed_pool to the import line and to __all__.

Change:
```python
from adbc_poolhouse._pool_factory import create_pool
```

To:
```python
from adbc_poolhouse._pool_factory import close_pool, create_pool, managed_pool
```

Add "close_pool" and "managed_pool" to __all__ in alphabetical order relative
to existing entries. Insert "close_pool" before "ConfigurationError" and
"managed_pool" before "MSSQLConfig":

```python
__all__ = [
    "close_pool",
    "ConfigurationError",
    "PoolhouseError",
    "WarehouseConfig",
    "BaseWarehouseConfig",
    "BigQueryConfig",
    "DatabricksConfig",
    "DuckDBConfig",
    "FlightSQLConfig",
    "managed_pool",
    "MSSQLConfig",
    "PostgreSQLConfig",
    "RedshiftConfig",
    "SnowflakeConfig",
    "TrinoConfig",
    "create_pool",
]
```

After editing, run prek to verify pre-commit hooks pass:
```bash
uv run prek
```
  </action>
  <verify>
    <automated>cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && uv run python -c "from adbc_poolhouse import close_pool, managed_pool, create_pool; print('OK')"</automated>
  </verify>
  <done>from adbc_poolhouse import close_pool, managed_pool succeeds; both symbols in __all__; prek passes</done>
</task>

</tasks>

<verification>
```bash
cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && uv run python -c "
from adbc_poolhouse import close_pool, managed_pool, create_pool, DuckDBConfig
import adbc_poolhouse
assert 'close_pool' in adbc_poolhouse.__all__
assert 'managed_pool' in adbc_poolhouse.__all__
print('All assertions passed')
"
```

Also confirm prek passes: `uv run prek`
</verification>

<success_criteria>
- close_pool and managed_pool importable from adbc_poolhouse
- Both in __all__
- close_pool calls pool.dispose() then pool._adbc_source.close()
- managed_pool is a @contextlib.contextmanager generator with explicit pool kwargs
- create_pool docstring no longer references pool._adbc_source directly for disposal
- prek passes (basedpyright + ruff)
</success_criteria>

<output>
After completion, create `.planning/phases/08-review-and-improve-docs/08-01-SUMMARY.md`
</output>
