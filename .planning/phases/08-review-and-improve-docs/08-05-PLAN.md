---
phase: 08-review-and-improve-docs
plan: "05"
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/src/guides/databricks.md
  - docs/src/guides/redshift.md
  - docs/src/guides/trino.md
  - docs/src/guides/mssql.md
  - docs/src/guides/teradata.md
autonomous: true
requirements: []

must_haves:
  truths:
    - "Databricks guide exists with Foundry driver notice instead of pip install"
    - "Redshift guide exists with Foundry driver notice instead of pip install"
    - "Trino guide exists with Foundry driver notice"
    - "MSSQL guide exists as stub (no pip install, Foundry notice, env prefix only)"
    - "Teradata guide exists as honest stub (no config class, Foundry notice, no invented fields)"
    - "None of the five pages reference _adbc_source"
  artifacts:
    - path: "docs/src/guides/databricks.md"
      provides: "Databricks warehouse guide (Foundry)"
      contains: "DATABRICKS_"
    - path: "docs/src/guides/redshift.md"
      provides: "Redshift warehouse guide (Foundry)"
      contains: "REDSHIFT_"
    - path: "docs/src/guides/trino.md"
      provides: "Trino warehouse guide (Foundry)"
      contains: "TRINO_"
    - path: "docs/src/guides/mssql.md"
      provides: "MSSQL warehouse guide stub (Foundry)"
      contains: "MSSQL_"
    - path: "docs/src/guides/teradata.md"
      provides: "Teradata stub page (no TeradataConfig class exists)"
      contains: "not yet implemented"
  key_links: []
---

<objective>
Create five warehouse guide pages for Foundry-distributed warehouses: Databricks,
Redshift, Trino, MSSQL, and a Teradata stub page. These warehouses have no PyPI
extras — their ADBC drivers are Foundry-distributed.

CRITICAL: TeradataConfig does not exist in the package. The teradata.md page must
be an honest stub stating the config class is not yet implemented. Do NOT invent
field names, env var prefixes, or code examples for Teradata.

Purpose: Even Foundry-distributed warehouses need discovery pages so users can
confirm backend support and find driver installation guidance.

Output: Five new markdown files in docs/src/guides/.
</objective>

<execution_context>
@/Users/paul/.claude/get-shit-done/workflows/execute-plan.md
@/Users/paul/.claude/get-shit-done/templates/summary.md
@.claude/skills/adbc-poolhouse-docs-author/SKILL.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@docs/src/guides/snowflake.md
@src/adbc_poolhouse/_databricks_config.py
@src/adbc_poolhouse/_redshift_config.py
@src/adbc_poolhouse/_trino_config.py
@src/adbc_poolhouse/_mssql_config.py

<interfaces>
<!-- Key fields per config class — extracted from source for executor reference -->

DatabricksConfig (env_prefix="DATABRICKS_"):
  uri: SecretStr | None = None   # DATABRICKS_URI — databricks://token:<token>@<host>:443/<http-path>
  host: str | None = None        # DATABRICKS_HOST — workspace hostname
  http_path: str | None = None   # DATABRICKS_HTTP_PATH — SQL warehouse or cluster path
  token: SecretStr | None = None # DATABRICKS_TOKEN — PAT token
  NOTE: Driver is Foundry-distributed (not on PyPI). No pip install extra.

RedshiftConfig (env_prefix="REDSHIFT_"):
  uri: str | None = None   # REDSHIFT_URI — redshift://[user:password@]host[:port]/dbname[?params]
  host: str | None = None  # REDSHIFT_HOST
  port: int | None = None  # REDSHIFT_PORT
  user: str | None = None  # REDSHIFT_USER
  password: SecretStr | None = None  # REDSHIFT_PASSWORD
  database: str | None = None  # REDSHIFT_DATABASE
  NOTE: Driver is Foundry-distributed (not on PyPI). No pip install extra.
  NOTE: Supports provisioned clusters (standard and IAM auth) and Redshift Serverless.

TrinoConfig (env_prefix="TRINO_"):
  uri: str | None = None     # TRINO_URI — trino://[user[:password]@]host[:port][/catalog[/schema]][?params]
  host: str | None = None    # TRINO_HOST
  port: int | None = None    # TRINO_PORT
  user: str | None = None    # TRINO_USER
  password: SecretStr | None = None  # TRINO_PASSWORD
  catalog: str | None = None  # TRINO_CATALOG
  NOTE: Driver is Foundry-distributed (not on PyPI). No pip install extra.

MSSQLConfig (env_prefix="MSSQL_"):
  uri: str | None = None     # MSSQL_URI — mssql://user:pass@host[:port][/instance][?params]
  host: str | None = None    # MSSQL_HOST
  port: int | None = None    # MSSQL_PORT
  user: str | None = None    # MSSQL_USER
  password: SecretStr | None = None  # MSSQL_PASSWORD
  database: str | None = None  # MSSQL_DATABASE
  trust_server_certificate: bool = False  # MSSQL_TRUST_SERVER_CERTIFICATE
  NOTE: Driver is Foundry-distributed. Covers SQL Server, Azure SQL, Azure Fabric, Synapse.
  NOTE: CONTEXT.md says stub page only — install + env var prefix, no auth examples

TeradataConfig: DOES NOT EXIST. No _teradata_config.py, no TeradataConfig class,
no TERADATA_ env prefix in source. Stub page only — no code examples.
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create databricks.md and redshift.md</name>
  <files>docs/src/guides/databricks.md, docs/src/guides/redshift.md</files>
  <action>
Create two Foundry-distributed warehouse guides. Neither has a PyPI extra — replace
the pip install section with a Foundry installation notice.

**docs/src/guides/databricks.md:**

```markdown
# Databricks guide

The Databricks ADBC driver is distributed via the ADBC Driver Foundry, not PyPI.
Follow your Foundry installation guide to install it before using `DatabricksConfig`.

`adbc-poolhouse` does not need a separate extra for Databricks:

```bash
pip install adbc-poolhouse
```

## Connection

`DatabricksConfig` connects to a Databricks SQL warehouse or all-purpose cluster
using a personal access token (PAT). Specify the connection as a URI or via
decomposed fields.

### URI

```python
from adbc_poolhouse import DatabricksConfig, create_pool

config = DatabricksConfig(
    uri="databricks://token:dapi...@adb-xxx.azuredatabricks.net:443/sql/1.0/warehouses/abc123",  # pragma: allowlist secret
)
pool = create_pool(config)
```

### Decomposed fields

```python
config = DatabricksConfig(
    host="adb-xxx.azuredatabricks.net",
    http_path="/sql/1.0/warehouses/abc123",
    token="dapi...",  # pragma: allowlist secret
)
pool = create_pool(config)
```

## Loading from environment variables

`DatabricksConfig` reads all fields from environment variables with the `DATABRICKS_` prefix:

```bash
export DATABRICKS_HOST=adb-xxx.azuredatabricks.net
export DATABRICKS_HTTP_PATH=/sql/1.0/warehouses/abc123
export DATABRICKS_TOKEN=dapi...
```

```python
config = DatabricksConfig()  # reads from env
```

## See also

- [Configuration reference](configuration.md) — env_prefix, pool tuning
- [Pool lifecycle](pool-lifecycle.md) — close_pool, pytest fixtures
```

---

**docs/src/guides/redshift.md:**

```markdown
# Redshift guide

The Redshift ADBC driver is distributed via the ADBC Driver Foundry, not PyPI.
Follow your Foundry installation guide to install it before using `RedshiftConfig`.

`adbc-poolhouse` does not need a separate extra for Redshift:

```bash
pip install adbc-poolhouse
```

## Connection

`RedshiftConfig` supports provisioned clusters (standard SQL auth and IAM) and
Redshift Serverless. Specify the connection as a URI or via decomposed fields.

### URI

```python
from adbc_poolhouse import RedshiftConfig, create_pool

config = RedshiftConfig(
    uri="redshift://me:s3cret@my-cluster.us-east-1.redshift.amazonaws.com:5439/mydb",  # pragma: allowlist secret
)
pool = create_pool(config)
```

### Decomposed fields

```python
config = RedshiftConfig(
    host="my-cluster.us-east-1.redshift.amazonaws.com",
    port=5439,
    user="me",
    password="s3cret",  # pragma: allowlist secret
    database="mydb",
)
pool = create_pool(config)
```

## Loading from environment variables

`RedshiftConfig` reads all fields from environment variables with the `REDSHIFT_` prefix:

```bash
export REDSHIFT_HOST=my-cluster.us-east-1.redshift.amazonaws.com
export REDSHIFT_USER=me
export REDSHIFT_PASSWORD=s3cret
export REDSHIFT_DATABASE=mydb
```

```python
config = RedshiftConfig()  # reads from env
```

## See also

- [Configuration reference](configuration.md) — env_prefix, pool tuning
- [Pool lifecycle](pool-lifecycle.md) — close_pool, pytest fixtures
```

Voice: terse, technical. Apply humanizer pass after writing both pages.
  </action>
  <verify>
    <automated>cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && test -f docs/src/guides/databricks.md && test -f docs/src/guides/redshift.md && echo "both exist"</automated>
  </verify>
  <done>databricks.md and redshift.md exist with Foundry driver notice, connection examples, env var section with correct prefix, See also</done>
</task>

<task type="auto">
  <name>Task 2: Create trino.md, mssql.md, and teradata.md (stub)</name>
  <files>docs/src/guides/trino.md, docs/src/guides/mssql.md, docs/src/guides/teradata.md</files>
  <action>
Create three more Foundry warehouse guides. MSSQL is a partial guide (install
notice + env prefix, no auth examples per CONTEXT.md). Teradata is an honest stub
with no code examples (TeradataConfig does not exist in source).

**docs/src/guides/trino.md:**

```markdown
# Trino guide

The Trino ADBC driver is distributed via the ADBC Driver Foundry, not PyPI.
Follow your Foundry installation guide to install it before using `TrinoConfig`.

`adbc-poolhouse` does not need a separate extra for Trino:

```bash
pip install adbc-poolhouse
```

## Connection

`TrinoConfig` supports URI-based or decomposed field connection specification.

### URI

```python
from adbc_poolhouse import TrinoConfig, create_pool

config = TrinoConfig(
    uri="trino://me:s3cret@trino.example.com:8443/my_catalog/my_schema",  # pragma: allowlist secret
)
pool = create_pool(config)
```

### Decomposed fields

```python
config = TrinoConfig(
    host="trino.example.com",
    port=8443,
    user="me",
    password="s3cret",  # pragma: allowlist secret
    catalog="my_catalog",
)
pool = create_pool(config)
```

## Loading from environment variables

`TrinoConfig` reads all fields from environment variables with the `TRINO_` prefix:

```bash
export TRINO_HOST=trino.example.com
export TRINO_USER=me
export TRINO_PASSWORD=s3cret
export TRINO_CATALOG=my_catalog
```

```python
config = TrinoConfig()  # reads from env
```

## See also

- [Configuration reference](configuration.md) — env_prefix, pool tuning
- [Pool lifecycle](pool-lifecycle.md) — close_pool, pytest fixtures
```

---

**docs/src/guides/mssql.md:**

MSSQL: stub page — install notice + env prefix only per CONTEXT.md decision.
MSSQLConfig covers SQL Server, Azure SQL, Azure SQL Managed Instance, Azure Fabric,
and Synapse Analytics.

```markdown
# MSSQL guide

The MSSQL ADBC driver is distributed via the ADBC Driver Foundry, not PyPI.
Follow your Foundry installation guide to install it before using `MSSQLConfig`.

`adbc-poolhouse` does not need a separate extra for MSSQL:

```bash
pip install adbc-poolhouse
```

`MSSQLConfig` covers Microsoft SQL Server, Azure SQL Database, Azure SQL Managed
Instance, Azure Synapse Analytics, and Azure Fabric SQL endpoint.

## Loading from environment variables

`MSSQLConfig` reads all fields from environment variables with the `MSSQL_` prefix:

```bash
export MSSQL_HOST=myserver.database.windows.net
export MSSQL_USER=me
export MSSQL_PASSWORD=s3cret
export MSSQL_DATABASE=mydb
```

```python
from adbc_poolhouse import MSSQLConfig
config = MSSQLConfig()  # reads from env
```

## See also

- [Configuration reference](configuration.md) — env_prefix, pool tuning, Foundry backends
- [API Reference](../reference/) — full MSSQLConfig field listing
```

---

**docs/src/guides/teradata.md:**

CRITICAL: TeradataConfig does not exist in the package. This is an honest stub.
Do NOT invent field names, env var prefixes (no TERADATA_ prefix exists in source),
or code examples. Do not reference TeradataConfig as if it were importable.

```markdown
# Teradata guide

!!! note "Not yet implemented"
    `TeradataConfig` is planned but not yet implemented. The page below describes
    what will be available when support is added.

The Teradata ADBC driver is distributed via the ADBC Driver Foundry, not PyPI.

Teradata support — including `TeradataConfig` and the matching ADBC driver integration
— is planned for a future release. Track progress or request prioritisation on the
[GitHub issue tracker](https://github.com/anentropic/adbc-poolhouse/issues).

## See also

- [Configuration reference](configuration.md) — Foundry-distributed backends
- [API Reference](../reference/) — currently available config classes
```

Voice: terse, technical. Apply humanizer pass after writing all three pages.
  </action>
  <verify>
    <automated>cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && test -f docs/src/guides/trino.md && test -f docs/src/guides/mssql.md && test -f docs/src/guides/teradata.md && echo "all three exist" && grep "not yet implemented\|not yet\|planned" docs/src/guides/teradata.md | head -3</automated>
  </verify>
  <done>trino.md and mssql.md exist with Foundry driver notice and correct env prefix; teradata.md is an honest stub stating TeradataConfig is not yet implemented; no invented fields in teradata.md</done>
</task>

</tasks>

<verification>
```bash
cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && \
  for f in docs/src/guides/databricks.md docs/src/guides/redshift.md docs/src/guides/trino.md docs/src/guides/mssql.md docs/src/guides/teradata.md; do
    test -f "$f" && echo "$f: OK" || echo "$f: MISSING"
  done && \
  grep -c "TeradataConfig\b" docs/src/guides/teradata.md && \
  echo "TeradataConfig count above — should appear only in 'not yet implemented' context, not as importable class"
```

Note: Full mkdocs build verification is in Plan 06 after nav is updated.
</verification>

<success_criteria>
- Five guide pages exist: databricks.md, redshift.md, trino.md, mssql.md, teradata.md
- Foundry pages (all five): no pip install [extra] command — Foundry driver notice instead
- databricks.md: URI and decomposed field examples, DATABRICKS_ env prefix
- redshift.md: URI and decomposed field examples, REDSHIFT_ env prefix
- trino.md: URI and decomposed field examples, TRINO_ env prefix
- mssql.md: MSSQL_ env prefix shown, no auth code examples (stub per CONTEXT.md)
- teradata.md: honest stub with no TeradataConfig code examples or invented fields
- No reference to pool._adbc_source in any of these five pages
</success_criteria>

<output>
After completion, create `.planning/phases/08-review-and-improve-docs/08-05-SUMMARY.md`
</output>
