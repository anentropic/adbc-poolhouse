---
phase: 03-config-layer
plan: 03
type: execute
wave: 2
depends_on:
  - 03-01
files_modified:
  - src/adbc_poolhouse/_bigquery_config.py
  - src/adbc_poolhouse/_postgresql_config.py
  - src/adbc_poolhouse/_flightsql_config.py
autonomous: true
requirements:
  - CFG-05

must_haves:
  truths:
    - "BigQueryConfig() constructs with all-optional fields"
    - "PostgreSQLConfig() constructs with all-optional fields (uri-primary design)"
    - "FlightSQLConfig(uri='grpc://localhost:8080') constructs successfully"
    - "BIGQUERY_PROJECT_ID env var populates BigQueryConfig.project_id"
    - "POSTGRESQL_URI env var populates PostgreSQLConfig.uri"
    - "FLIGHTSQL_URI env var populates FlightSQLConfig.uri"
    - "All three configs are instances of WarehouseConfig Protocol"
  artifacts:
    - path: "src/adbc_poolhouse/_bigquery_config.py"
      provides: "BigQueryConfig with GCP auth fields"
      exports: ["BigQueryConfig"]
    - path: "src/adbc_poolhouse/_postgresql_config.py"
      provides: "PostgreSQLConfig with URI-primary design"
      exports: ["PostgreSQLConfig"]
    - path: "src/adbc_poolhouse/_flightsql_config.py"
      provides: "FlightSQLConfig with gRPC connection and TLS fields"
      exports: ["FlightSQLConfig"]
  key_links:
    - from: "src/adbc_poolhouse/_bigquery_config.py"
      to: "src/adbc_poolhouse/_base_config.py"
      via: "class BigQueryConfig(BaseWarehouseConfig)"
      pattern: "class BigQueryConfig.*BaseWarehouseConfig"
    - from: "src/adbc_poolhouse/_postgresql_config.py"
      to: "src/adbc_poolhouse/_base_config.py"
      via: "class PostgreSQLConfig(BaseWarehouseConfig)"
      pattern: "class PostgreSQLConfig.*BaseWarehouseConfig"
    - from: "src/adbc_poolhouse/_flightsql_config.py"
      to: "src/adbc_poolhouse/_base_config.py"
      via: "class FlightSQLConfig(BaseWarehouseConfig)"
      pattern: "class FlightSQLConfig.*BaseWarehouseConfig"
---

<objective>
Implement the three Apache ADBC backend configs: BigQuery, PostgreSQL, and FlightSQL.

Purpose: These three complete the set of PyPI-available Apache ADBC backends. PostgreSQL and FlightSQL use URI-primary designs (all connection params in the URI string). BigQuery has a GCP auth-oriented field set. These are simpler than Snowflake — no cross-field validators required.
Output: _bigquery_config.py, _postgresql_config.py, _flightsql_config.py
</objective>

<execution_context>
@/Users/paul/.claude/get-shit-done/workflows/execute-plan.md
@/Users/paul/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-config-layer/03-RESEARCH.md
@.planning/phases/03-config-layer/03-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create _bigquery_config.py and _postgresql_config.py</name>
  <files>src/adbc_poolhouse/_bigquery_config.py, src/adbc_poolhouse/_postgresql_config.py</files>
  <action>
**BigQueryConfig** — `src/adbc_poolhouse/_bigquery_config.py`:

```python
from __future__ import annotations

from pydantic import SecretStr
from pydantic_settings import SettingsConfigDict

from adbc_poolhouse._base_config import BaseWarehouseConfig


class BigQueryConfig(BaseWarehouseConfig):
    """BigQuery warehouse configuration.

    Supports SDK default auth (ADC), JSON credential file, JSON credential
    string, and user authentication flows.

    Pool tuning fields are inherited and loaded from BIGQUERY_* env vars.
    """

    model_config = SettingsConfigDict(env_prefix='BIGQUERY_')

    auth_type: str | None = None
    """Auth method: 'bigquery' (SDK default/ADC), 'json_credential_file',
    'json_credential_string', 'user_authentication'. Env: BIGQUERY_AUTH_TYPE."""

    auth_credentials: SecretStr | None = None
    """JSON credentials file path or encoded credential string, depending on
    auth_type. Env: BIGQUERY_AUTH_CREDENTIALS."""

    auth_client_id: str | None = None
    """OAuth client ID for user_authentication flow. Env: BIGQUERY_AUTH_CLIENT_ID."""

    auth_client_secret: SecretStr | None = None
    """OAuth client secret for user_authentication flow. Env: BIGQUERY_AUTH_CLIENT_SECRET."""

    auth_refresh_token: SecretStr | None = None
    """OAuth refresh token for user_authentication flow. Env: BIGQUERY_AUTH_REFRESH_TOKEN."""

    project_id: str | None = None
    """GCP project ID. Env: BIGQUERY_PROJECT_ID."""

    dataset_id: str | None = None
    """Default dataset. Env: BIGQUERY_DATASET_ID."""

    def _adbc_driver_key(self) -> str:
        return 'bigquery'
```

**PostgreSQLConfig** — `src/adbc_poolhouse/_postgresql_config.py`:

```python
from __future__ import annotations

from pydantic_settings import SettingsConfigDict

from adbc_poolhouse._base_config import BaseWarehouseConfig


class PostgreSQLConfig(BaseWarehouseConfig):
    """PostgreSQL warehouse configuration.

    The PostgreSQL ADBC driver wraps libpq. All connection parameters
    (host, port, user, password, dbname, sslmode, etc.) are specified
    in the URI following libpq connection string format:
    postgresql://user:password@host:5432/dbname?sslmode=require

    Pool tuning fields are inherited and loaded from POSTGRESQL_* env vars.
    """

    model_config = SettingsConfigDict(env_prefix='POSTGRESQL_')

    uri: str | None = None
    """libpq connection URI. Env: POSTGRESQL_URI.
    Format: postgresql://[user[:password]@][host][:port][/dbname][?params]"""

    use_copy: bool = True
    """Use PostgreSQL COPY protocol for bulk query execution (driver default:
    True). Disable if COPY triggers permission errors. Env: POSTGRESQL_USE_COPY."""

    def _adbc_driver_key(self) -> str:
        return 'postgresql'
```

**Implementation notes:**
- BigQuery: `auth_credentials` is `SecretStr` because it may contain inline JSON with service account private key material.
- PostgreSQL: `uri` is `str | None = None` (not required) because consumers may provide it via env var `POSTGRESQL_URI`. No individual host/port fields — libpq params belong in the URI.
- No cross-field validators needed for either model.
  </action>
  <verify>
    <automated>cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && uv run python -c "
from adbc_poolhouse._bigquery_config import BigQueryConfig
from adbc_poolhouse._postgresql_config import PostgreSQLConfig
from adbc_poolhouse._base_config import WarehouseConfig

bq = BigQueryConfig()
assert bq.pool_size == 5
assert bq.project_id is None
assert isinstance(bq, WarehouseConfig)
print('PASS: BigQueryConfig')

pg = PostgreSQLConfig()
assert pg.use_copy is True
assert pg.uri is None
assert isinstance(pg, WarehouseConfig)

import os
os.environ['POSTGRESQL_URI'] = 'postgresql://user:pass@localhost/db'
pg2 = PostgreSQLConfig()
assert pg2.uri == 'postgresql://user:pass@localhost/db'
del os.environ['POSTGRESQL_URI']
print('PASS: PostgreSQLConfig env var loading')
"</automated>
  </verify>
  <done>BigQueryConfig and PostgreSQLConfig exist; both construct with no args; PostgreSQLConfig.use_copy defaults True; POSTGRESQL_URI env var loads correctly; both isinstance WarehouseConfig Protocol.</done>
</task>

<task type="auto">
  <name>Task 2: Create _flightsql_config.py</name>
  <files>src/adbc_poolhouse/_flightsql_config.py</files>
  <action>
Create `src/adbc_poolhouse/_flightsql_config.py`:

```python
from __future__ import annotations

from pydantic import SecretStr
from pydantic_settings import SettingsConfigDict

from adbc_poolhouse._base_config import BaseWarehouseConfig


class FlightSQLConfig(BaseWarehouseConfig):
    """FlightSQL warehouse configuration.

    Connects to any Apache Arrow Flight SQL server (e.g. Dremio, InfluxDB,
    DuckDB server mode, custom Flight SQL implementations).

    Pool tuning fields are inherited and loaded from FLIGHTSQL_* env vars.
    """

    model_config = SettingsConfigDict(env_prefix='FLIGHTSQL_')

    uri: str | None = None
    """gRPC endpoint URI. Env: FLIGHTSQL_URI.
    Format: grpc://host:port (plaintext) or grpc+tls://host:port (TLS)."""

    # --- Authentication ---
    username: str | None = None
    """Username for HTTP-style basic auth. Env: FLIGHTSQL_USERNAME."""

    password: SecretStr | None = None
    """Password for HTTP-style basic auth. Env: FLIGHTSQL_PASSWORD."""

    authorization_header: SecretStr | None = None
    """Custom authorization header value (overrides username/password if set).
    Env: FLIGHTSQL_AUTHORIZATION_HEADER."""

    # --- mTLS ---
    mtls_cert_chain: str | None = None
    """mTLS certificate chain (PEM). Env: FLIGHTSQL_MTLS_CERT_CHAIN."""

    mtls_private_key: SecretStr | None = None
    """mTLS private key (PEM). Env: FLIGHTSQL_MTLS_PRIVATE_KEY."""

    # --- TLS ---
    tls_root_certs: str | None = None
    """Root CA certificate(s) in PEM format. Env: FLIGHTSQL_TLS_ROOT_CERTS."""

    tls_skip_verify: bool = False
    """Disable TLS certificate verification. Env: FLIGHTSQL_TLS_SKIP_VERIFY."""

    tls_override_hostname: str | None = None
    """Override the TLS hostname for SNI. Env: FLIGHTSQL_TLS_OVERRIDE_HOSTNAME."""

    # --- Timeouts (float seconds) ---
    connect_timeout: float | None = None
    """Connection timeout in seconds. Env: FLIGHTSQL_CONNECT_TIMEOUT."""

    query_timeout: float | None = None
    """Query execution timeout in seconds. Env: FLIGHTSQL_QUERY_TIMEOUT."""

    fetch_timeout: float | None = None
    """Result fetch timeout in seconds. Env: FLIGHTSQL_FETCH_TIMEOUT."""

    update_timeout: float | None = None
    """DML update timeout in seconds. Env: FLIGHTSQL_UPDATE_TIMEOUT."""

    # --- gRPC options ---
    authority: str | None = None
    """Override gRPC authority header. Env: FLIGHTSQL_AUTHORITY."""

    max_msg_size: int | None = None
    """Maximum gRPC message size in bytes (driver default: 16 MiB).
    Env: FLIGHTSQL_MAX_MSG_SIZE."""

    with_cookie_middleware: bool = False
    """Enable gRPC cookie middleware (required by some servers for session
    management). Env: FLIGHTSQL_WITH_COOKIE_MIDDLEWARE."""

    def _adbc_driver_key(self) -> str:
        return 'flightsql'
```

**Implementation notes:**
- `uri` is `str | None = None` (not required) so consumers can supply via `FLIGHTSQL_URI` env var.
- `mtls_private_key` is `SecretStr` — private key material must be masked in repr and logs.
- `authorization_header` is `SecretStr` — may contain raw bearer tokens.
- `connect_timeout`, `query_timeout`, etc. are `float | None` — seconds as floating point (e.g. `1.5` for 1500ms).
- No cross-field validators needed.
  </action>
  <verify>
    <automated>cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && uv run python -c "
from adbc_poolhouse._flightsql_config import FlightSQLConfig
from adbc_poolhouse._base_config import WarehouseConfig

# Default construction
f = FlightSQLConfig()
assert f.pool_size == 5
assert f.tls_skip_verify is False
assert f.with_cookie_middleware is False
assert f.uri is None
assert isinstance(f, WarehouseConfig)
print('PASS: FlightSQLConfig defaults')

# With URI
import os
os.environ['FLIGHTSQL_URI'] = 'grpc://localhost:8080'
f2 = FlightSQLConfig()
assert f2.uri == 'grpc://localhost:8080'
del os.environ['FLIGHTSQL_URI']
print('PASS: FlightSQLConfig URI env var')
"</automated>
  </verify>
  <done>FlightSQLConfig exists with all gRPC, auth, TLS, and timeout fields; defaults are correct; FLIGHTSQL_URI env var loads; isinstance WarehouseConfig Protocol.</done>
</task>

</tasks>

<verification>
```bash
cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse
uv run python -c "
from adbc_poolhouse._bigquery_config import BigQueryConfig
from adbc_poolhouse._postgresql_config import PostgreSQLConfig
from adbc_poolhouse._flightsql_config import FlightSQLConfig
from adbc_poolhouse._base_config import WarehouseConfig

for cls in [BigQueryConfig, PostgreSQLConfig]:
    obj = cls()
    assert isinstance(obj, WarehouseConfig)

f = FlightSQLConfig()
assert isinstance(f, WarehouseConfig)
print('PASS: All three Apache backend configs valid')
"
uv run prek 2>&1 | tail -5
```
</verification>

<success_criteria>
- `_bigquery_config.py`, `_postgresql_config.py`, `_flightsql_config.py` all exist
- Each constructs with no required args (except FlightSQLConfig.uri can be None)
- env_prefix isolation: BIGQUERY_*, POSTGRESQL_*, FLIGHTSQL_* each only populate their own config
- All three are instances of WarehouseConfig Protocol
- prek passes
</success_criteria>

<output>
After completion, create `.planning/phases/03-config-layer/03-03-SUMMARY.md` with:
- Files created and key field decisions
- Any deviations from RESEARCH.md field sets
</output>
