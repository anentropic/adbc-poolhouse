---
phase: 04-translation-and-driver-detection
plan: "02"
type: execute
wave: 1
depends_on: []
files_modified:
  - src/adbc_poolhouse/_snowflake_translator.py
  - src/adbc_poolhouse/_databricks_translator.py
  - src/adbc_poolhouse/_redshift_translator.py
  - src/adbc_poolhouse/_trino_translator.py
  - src/adbc_poolhouse/_mssql_translator.py
  - src/adbc_poolhouse/_teradata_translator.py
autonomous: true
requirements:
  - TRANS-02
  - TRANS-04
  - TRANS-05

must_haves:
  truths:
    - "translate_snowflake maps all auth method fields to verified ADBC key strings"
    - "translate_snowflake uses 'username'/'password' plain string keys (NOT 'adbc.snowflake.sql.user')"
    - "translate_snowflake uses config.schema_ (trailing underscore) to produce ADBC key 'adbc.snowflake.sql.schema'"
    - "All Foundry translators (Databricks, Redshift, Trino, MSSQL, Teradata) return uri-keyed dict"
    - "DatabricksConfig.uri is SecretStr — translated with .get_secret_value()"
    - "translate_teradata has TODO comment noting LOW confidence field names"
    - "None of the six translator files import any ADBC driver package at module level"
  artifacts:
    - path: "src/adbc_poolhouse/_snowflake_translator.py"
      provides: "translate_snowflake() pure function"
      exports: ["translate_snowflake"]
      min_lines: 60
    - path: "src/adbc_poolhouse/_databricks_translator.py"
      provides: "translate_databricks() pure function"
      exports: ["translate_databricks"]
    - path: "src/adbc_poolhouse/_redshift_translator.py"
      provides: "translate_redshift() pure function"
      exports: ["translate_redshift"]
    - path: "src/adbc_poolhouse/_trino_translator.py"
      provides: "translate_trino() pure function"
      exports: ["translate_trino"]
    - path: "src/adbc_poolhouse/_mssql_translator.py"
      provides: "translate_mssql() pure function"
      exports: ["translate_mssql"]
    - path: "src/adbc_poolhouse/_teradata_translator.py"
      provides: "translate_teradata() pure function with LOW confidence comment"
      exports: ["translate_teradata"]
  key_links:
    - from: "translate_snowflake"
      to: "_snowflake_config.SnowflakeConfig"
      via: "import at module level"
      pattern: "from adbc_poolhouse._snowflake_config import SnowflakeConfig"
    - from: "translate_snowflake"
      to: "config.schema_"
      via: "attribute access in translator body"
      pattern: "config\\.schema_"
---

<objective>
Implement pure translator functions for Snowflake (TRANS-02) and all five Foundry-distributed backends — Databricks, Redshift, Trino, MSSQL, Teradata (TRANS-04). All six translators are pure functions: no ADBC imports, return dict[str, str] (TRANS-05).

Purpose: Snowflake is the most complex translator (28 ADBC key mappings, multiple auth methods, SecretStr fields, bool-to-string conversions). Foundry translators are simpler (URI-only model) but require correct handling of SecretStr on DatabricksConfig.

Output: Six translator source files, each a single pure function.
</objective>

<execution_context>
@/Users/paul/.claude/get-shit-done/workflows/execute-plan.md
@/Users/paul/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-translation-and-driver-detection/04-RESEARCH.md
@src/adbc_poolhouse/_snowflake_config.py
@src/adbc_poolhouse/_databricks_config.py
@src/adbc_poolhouse/_redshift_config.py
@src/adbc_poolhouse/_trino_config.py
@src/adbc_poolhouse/_mssql_config.py
@src/adbc_poolhouse/_teradata_config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Snowflake translator</name>
  <files>
    src/adbc_poolhouse/_snowflake_translator.py
  </files>
  <action>
Create `src/adbc_poolhouse/_snowflake_translator.py` implementing `translate_snowflake(config: SnowflakeConfig) -> dict[str, str]`.

Begin with `from __future__ import annotations`. Import only from `adbc_poolhouse._snowflake_config`.

Map every SnowflakeConfig field to its verified ADBC key string per the RESEARCH.md key reference table. Critical rules:

**Identity (always include):**
- `config.account` → `"adbc.snowflake.sql.account"` (required field, always present)

**Auth (include only if not None):**
- `config.user` → `"username"` (NOT "adbc.snowflake.sql.user" — verified plain key)
- `config.password` → `"password"` (SecretStr → `.get_secret_value()`)
- `config.auth_type` → `"adbc.snowflake.sql.auth_type"`

**JWT / private key (include only if not None):**
- `config.private_key_path` → `"adbc.snowflake.sql.client_option.jwt_private_key"` (Path → `str(val)`)
- `config.private_key_pem` → `"adbc.snowflake.sql.client_option.jwt_private_key_pkcs8_value"` (SecretStr)
- `config.private_key_passphrase` → `"adbc.snowflake.sql.client_option.jwt_private_key_pkcs8_password"` (SecretStr)
- `config.jwt_expire_timeout` → `"adbc.snowflake.sql.client_option.jwt_expire_timeout"` (str)

**OAuth / Okta / WIF (include only if not None):**
- `config.oauth_token` → `"adbc.snowflake.sql.client_option.auth_token"` (SecretStr)
- `config.okta_url` → `"adbc.snowflake.sql.client_option.okta_url"` (str)
- `config.identity_provider` → `"adbc.snowflake.sql.client_option.identity_provider"` (str)

**Session / scope (include only if not None):**
- `config.database` → `"adbc.snowflake.sql.db"` (str, optional)
- `config.schema_` → `"adbc.snowflake.sql.schema"` (CRITICAL: attribute is schema_ with trailing underscore; ADBC key has no underscore)
- `config.warehouse` → `"adbc.snowflake.sql.warehouse"` (str)
- `config.role` → `"adbc.snowflake.sql.role"` (str)
- `config.region` → `"adbc.snowflake.sql.region"` (str)

**Connection (include only if not None):**
- `config.host` → `"adbc.snowflake.sql.uri.host"` (str)
- `config.port` → `"adbc.snowflake.sql.uri.port"` (int → str)
- `config.protocol` → `"adbc.snowflake.sql.uri.protocol"` (str)

**Timeouts (include only if not None):**
- `config.login_timeout` → `"adbc.snowflake.sql.client_option.login_timeout"` (str)
- `config.request_timeout` → `"adbc.snowflake.sql.client_option.request_timeout"` (str)
- `config.client_timeout` → `"adbc.snowflake.sql.client_option.client_timeout"` (str)

**Boolean flags (always include — these have explicit defaults in SnowflakeConfig):**
- `config.tls_skip_verify` → `"adbc.snowflake.sql.client_option.tls_skip_verify"` (bool → `str(val).lower()`)
- `config.ocsp_fail_open_mode` → `"adbc.snowflake.sql.client_option.ocsp_fail_open_mode"` (bool → `str(val).lower()`)
- `config.keep_session_alive` → `"adbc.snowflake.sql.client_option.keep_session_alive"` (bool → `str(val).lower()`)
- `config.disable_telemetry` → `"adbc.snowflake.sql.client_option.disable_telemetry"` (bool → `str(val).lower()`)
- `config.cache_mfa_token` → `"adbc.snowflake.sql.client_option.cache_mfa_token"` (bool → `str(val).lower()`)
- `config.store_temp_creds` → `"adbc.snowflake.sql.client_option.store_temp_creds"` (bool → `str(val).lower()`)

**Misc (include only if not None):**
- `config.app_name` → `"adbc.snowflake.sql.client_option.app_name"` (str)

Add a module docstring: "Verified against installed adbc_driver_snowflake source. Key 'username' and 'password' are plain string keys, not prefixed with 'adbc.snowflake.sql.*'."

Note: Pool tuning fields (pool_size, max_overflow, timeout, recycle) are NOT translated — they are handled by create_pool() in Phase 5.
  </action>
  <verify>
    <automated>cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && python -c "
from adbc_poolhouse._snowflake_translator import translate_snowflake
from adbc_poolhouse._snowflake_config import SnowflakeConfig

# Minimal config (only required field)
config = SnowflakeConfig(account='myorg-myaccount')
result = translate_snowflake(config)
assert result.get('adbc.snowflake.sql.account') == 'myorg-myaccount', f'account key: {result}'
assert 'username' not in result, 'user should be absent when not set'
# Bool flags always present
assert result.get('adbc.snowflake.sql.client_option.tls_skip_verify') == 'false', f'tls_skip_verify: {result}'
assert result.get('adbc.snowflake.sql.client_option.disable_telemetry') in ('true', 'false'), f'disable_telemetry: {result}'
# schema_ attribute → ADBC key without trailing underscore
config2 = SnowflakeConfig(account='myorg', schema_='PUBLIC')
result2 = translate_snowflake(config2)
assert result2.get('adbc.snowflake.sql.schema') == 'PUBLIC', f'schema: {result2}'
# All values are strings
assert all(isinstance(v, str) for v in result.values()), f'Non-string values: {result}'
print('OK')
"</automated>
    <manual>Confirm no adbc_driver_snowflake import at module level. Verify "password" and "username" keys (not prefixed with adbc.snowflake.sql.*).</manual>
  </verify>
  <done>
    - translate_snowflake(SnowflakeConfig(account="myorg")) returns dict with "adbc.snowflake.sql.account" = "myorg"
    - User/password use plain "username"/"password" keys (not "adbc.snowflake.sql.user")
    - schema_ attribute is accessed with trailing underscore, maps to "adbc.snowflake.sql.schema" key (no underscore)
    - All six boolean flags always appear in output as "true"/"false" strings
    - All output values are str type (no booleans, Paths, SecretStr objects, or None)
    - No adbc_driver_* import at module level
  </done>
</task>

<task type="auto">
  <name>Task 2: Foundry backend translators (Databricks, Redshift, Trino, MSSQL, Teradata)</name>
  <files>
    src/adbc_poolhouse/_databricks_translator.py
    src/adbc_poolhouse/_redshift_translator.py
    src/adbc_poolhouse/_trino_translator.py
    src/adbc_poolhouse/_mssql_translator.py
    src/adbc_poolhouse/_teradata_translator.py
  </files>
  <action>
All Foundry backends use URI-only connection model. Create five translator files following this pattern (adjust imports and field access per each config class):

**`src/adbc_poolhouse/_databricks_translator.py`:**
```python
from __future__ import annotations

from adbc_poolhouse._databricks_config import DatabricksConfig


def translate_databricks(config: DatabricksConfig) -> dict[str, str]:
    """Translate DatabricksConfig to ADBC driver kwargs.

    Databricks uses URI-only connection model. Driver name: 'databricks'.
    Verified from docs.adbc-drivers.org.
    Note: DatabricksConfig.uri is SecretStr (URI may embed PAT token).
    """
    kwargs: dict[str, str] = {}
    if config.uri is not None:
        kwargs["uri"] = config.uri.get_secret_value()
    return kwargs
```

**`src/adbc_poolhouse/_redshift_translator.py`:**
```python
from __future__ import annotations

from adbc_poolhouse._redshift_config import RedshiftConfig


def translate_redshift(config: RedshiftConfig) -> dict[str, str]:
    """Translate RedshiftConfig to ADBC driver kwargs.

    Redshift uses URI-only connection model. Driver name: 'redshift'.
    Verified from docs.adbc-drivers.org.
    Note: RedshiftConfig.uri is plain str (credentials are separate IAM fields).
    """
    kwargs: dict[str, str] = {}
    if config.uri is not None:
        kwargs["uri"] = config.uri
    return kwargs
```

**`src/adbc_poolhouse/_trino_translator.py`:**

Check TrinoConfig fields first (read src/adbc_poolhouse/_trino_config.py). If TrinoConfig has a `uri` field, use it. If it has decomposed host/port/user/password fields, build a URI or pass them as individual kwargs per the actual field names in the config. Map ssl field to "ssl" key if present (str(val).lower() for bool). Add `# pragma: allowlist secret` on any line with password string literals. No ADBC imports.

**`src/adbc_poolhouse/_mssql_translator.py`:**

Check MSSQLConfig fields first (read src/adbc_poolhouse/_mssql_config.py). If MSSQLConfig has a `uri` field, map it directly. Include other supported fields if present. Driver name: 'mssql'. No ADBC imports.

**`src/adbc_poolhouse/_teradata_translator.py`:**

```python
from __future__ import annotations

# TODO: LOW CONFIDENCE — TeradataConfig field names were triangulated from Teradata JDBC
# and teradatasql Python driver docs because the Columnar ADBC Teradata driver docs
# returned 404 at Phase 3 and Phase 4 research time. Verify field names against the
# actual Teradata Foundry driver when docs become available.
# Driver name: 'teradata' (LOW confidence — inferred from pattern, docs returned 404).

from adbc_poolhouse._teradata_config import TeradataConfig


def translate_teradata(config: TeradataConfig) -> dict[str, str]:
    """Translate TeradataConfig to ADBC driver kwargs.

    WARNING: LOW confidence. Teradata Foundry driver docs were unavailable (404)
    at research time. Field names triangulated from JDBC and teradatasql docs.
    Verify against actual driver before production use.
    """
    kwargs: dict[str, str] = {}
    # URI-first: if uri field exists on config, use it
    if hasattr(config, 'uri') and config.uri is not None:  # type: ignore[attr-defined]
        kwargs["uri"] = str(config.uri)
        return kwargs
    # Individual fields as fallback (LOW confidence key names)
    # Read TeradataConfig to determine actual field names before implementing
    ...
    return kwargs
```

After writing _teradata_translator.py, read `src/adbc_poolhouse/_teradata_config.py` to determine actual field names and implement the body fully. Do NOT use `...` as a placeholder — write the complete function body mapping each TeradataConfig field. For any field where the ADBC key name is uncertain, add an inline comment `# LOW confidence key name`.

All five files: begin with `from __future__ import annotations`, no ADBC driver imports.
  </action>
  <verify>
    <automated>cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && python -c "
from adbc_poolhouse._databricks_translator import translate_databricks
from adbc_poolhouse._redshift_translator import translate_redshift
from adbc_poolhouse._trino_translator import translate_trino
from adbc_poolhouse._mssql_translator import translate_mssql
from adbc_poolhouse._teradata_translator import translate_teradata
from adbc_poolhouse._databricks_config import DatabricksConfig
from adbc_poolhouse._redshift_config import RedshiftConfig
from adbc_poolhouse._trino_config import TrinoConfig
from adbc_poolhouse._mssql_config import MSSQLConfig
from adbc_poolhouse._teradata_config import TeradataConfig

# Each returns dict[str, str]
configs = [
    (translate_databricks, DatabricksConfig()),
    (translate_redshift, RedshiftConfig()),
    (translate_trino, TrinoConfig()),
    (translate_mssql, MSSQLConfig()),
    (translate_teradata, TeradataConfig()),
]
for fn, cfg in configs:
    result = fn(cfg)
    assert isinstance(result, dict), f'{fn.__name__} must return dict'
    assert all(isinstance(k, str) and isinstance(v, str) for k, v in result.items()), f'{fn.__name__} non-string values: {result}'

# Databricks uri is SecretStr
from pydantic import SecretStr
d = DatabricksConfig(uri=SecretStr('databricks://host/catalog'))
r = translate_databricks(d)
assert r.get('uri') == 'databricks://host/catalog', f'Databricks uri: {r}'

print('OK')
"</automated>
    <manual>Check _teradata_translator.py has TODO comment noting LOW confidence. Confirm _databricks_translator.py calls .get_secret_value() on uri.</manual>
  </verify>
  <done>
    - All five Foundry translators importable and callable
    - Each returns dict[str, str] with no None values
    - DatabricksConfig.uri (SecretStr) is extracted with .get_secret_value()
    - _teradata_translator.py has a prominent TODO comment noting LOW confidence field names
    - No ADBC driver package imported at module level in any of the five files
  </done>
</task>

</tasks>

<verification>
Run prek on the six new translator files:

```bash
cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && prek run --all-files 2>&1 | tail -20
```

Confirm all six translators importable without ADBC drivers installed:

```bash
cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && python -c "
from adbc_poolhouse._snowflake_translator import translate_snowflake
from adbc_poolhouse._databricks_translator import translate_databricks
from adbc_poolhouse._redshift_translator import translate_redshift
from adbc_poolhouse._trino_translator import translate_trino
from adbc_poolhouse._mssql_translator import translate_mssql
from adbc_poolhouse._teradata_translator import translate_teradata
print('All 6 Foundry+Snowflake translators importable')
"
```
</verification>

<success_criteria>
- translate_snowflake correctly maps all 28 Snowflake ADBC key strings per RESEARCH.md reference table
- translate_snowflake uses "username"/"password" plain keys (not "adbc.snowflake.sql.user")
- All five Foundry translators return dict[str, str]; DatabricksConfig.uri extracted with .get_secret_value()
- translate_teradata has TODO comment noting LOW confidence
- prek passes with zero violations
</success_criteria>

<output>
After completion, create `.planning/phases/04-translation-and-driver-detection/04-02-SUMMARY.md`
</output>
