---
phase: 07-documentation-and-pypi-publication
plan: "03"
type: execute
wave: 1
depends_on: []
files_modified:
  - docs/src/index.md
  - docs/src/guides/pool-lifecycle.md
  - docs/src/guides/consumer-patterns.md
  - docs/src/guides/configuration.md
  - docs/src/guides/snowflake.md
  - docs/src/changelog.md
  - mkdocs.yml
autonomous: true
requirements:
  - DOCS-02
  - DOCS-03
  - DOCS-04

must_haves:
  truths:
    - "The quickstart guide produces a working DuckDB pool following the documented steps"
    - "Consumer patterns guide shows two complete working examples: ORM direct config and dbt-open-sl shim"
    - "Pool lifecycle guide covers pool.dispose(), fixture teardown pattern, and common mistakes"
    - "mkdocs nav has four top-level sections: Getting Started, Guides, API Reference, Changelog"
    - "`uv run mkdocs build --strict` passes after all guide files and nav changes are in place"
  artifacts:
    - path: "docs/src/index.md"
      provides: "Quickstart guide (install + first working DuckDB pool)"
      contains: "create_pool"
    - path: "docs/src/guides/pool-lifecycle.md"
      provides: "Pool lifecycle guide (dispose, fixture teardown, common mistakes)"
      contains: "pool.dispose()"
    - path: "docs/src/guides/consumer-patterns.md"
      provides: "Two consumer pattern examples"
      contains: "dbt"
    - path: "docs/src/guides/configuration.md"
      provides: "Configuration reference guide"
      contains: "env_prefix"
    - path: "docs/src/guides/snowflake.md"
      provides: "Snowflake-specific guide"
      contains: "SnowflakeConfig"
    - path: "docs/src/changelog.md"
      provides: "Changelog placeholder page"
      contains: "releases"
    - path: "mkdocs.yml"
      provides: "Updated nav with four sections"
      contains: "Getting Started"
  key_links:
    - from: "mkdocs.yml nav"
      to: "docs/src/guides/*.md"
      via: "nav entry referencing file"
      pattern: "guides/"
    - from: "docs/src/index.md"
      to: "create_pool, DuckDBConfig"
      via: "code example import"
      pattern: "from adbc_poolhouse import"
---

<objective>
Write all four guide pages, the quickstart (index.md), the changelog placeholder, and restructure mkdocs.yml nav to the required four-section layout (Getting Started / Guides / API Reference / Changelog). All files must be created before nav is updated to avoid `mkdocs build --strict` failures.

Purpose: DOCS-02, DOCS-03, DOCS-04 deliver the consumer-facing documentation that makes the library usable. The nav restructure makes the site match the CONTEXT.md locked decision.
Output: Six new/updated `.md` files + updated `mkdocs.yml`
</objective>

<execution_context>
@/Users/paul/.claude/get-shit-done/workflows/execute-plan.md
@/Users/paul/.claude/get-shit-done/templates/summary.md
@.claude/skills/adbc-poolhouse-docs-author/SKILL.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-documentation-and-pypi-publication/07-CONTEXT.md
@.planning/phases/07-documentation-and-pypi-publication/07-RESEARCH.md

<interfaces>
<!-- Public API for examples — all importable from adbc_poolhouse -->
from adbc_poolhouse import (
    create_pool,
    DuckDBConfig,
    SnowflakeConfig,
    PostgreSQLConfig,
    PoolhouseError,
    ConfigurationError,
)

<!-- Pool connect pattern (ADBC cursor, not SQLAlchemy ORM) -->
pool = create_pool(config)
with pool.connect() as conn:
    cursor = conn.cursor()
    cursor.execute("SELECT 42 AS answer")
    row = cursor.fetchone()

<!-- Teardown pattern (from Phase 5 implementation) -->
pool.dispose()
pool._adbc_source.close()  # close the source connection held by the pool

<!-- DuckDB in-memory NOTE: pool_size=1 enforced (validator raises ValueError for >1) -->
<!-- DuckDB file-backed: shareable across pool connections; use for quickstart -->
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write guide pages and quickstart (DOCS-02, DOCS-03, DOCS-04)</name>
  <files>
    docs/src/index.md
    docs/src/guides/pool-lifecycle.md
    docs/src/guides/consumer-patterns.md
    docs/src/guides/configuration.md
    docs/src/guides/snowflake.md
    docs/src/changelog.md
  </files>
  <action>
Create the `docs/src/guides/` directory (if it does not exist) and write all six files. Write files BEFORE updating mkdocs.yml (Pitfall 6: missing files cause `--strict` build failure).

**IMPORTANT — Anti-patterns to avoid:**
- Do NOT write `>>>` doctest-style prompts; use plain code blocks
- Do NOT hand-write any file under `docs/src/reference/` — auto-generated
- Do NOT use promotional language (powerful, seamlessly, effortlessly) or AI vocabulary (leverage, delve)
- Apply humanizer pass to all prose before saving

---

**`docs/src/index.md`** — Quickstart (DOCS-02):

Replace the TODO placeholder with full quickstart prose. Audience: Python developers who need a connection pool in under 5 minutes.

Structure:
1. One-sentence description of what adbc-poolhouse does
2. Installation section: `pip install adbc-poolhouse` and `uv add adbc-poolhouse`
3. DuckDB example (no credentials required): full working code block showing import, config, create_pool, pool.connect() cursor usage, pool.dispose()
4. What's next: links to Guides section
5. "See also" section at bottom

DuckDB code example to include:
```python
from adbc_poolhouse import DuckDBConfig, create_pool

# File-backed database (connections share the same file)
config = DuckDBConfig(database="/tmp/warehouse.db")
pool = create_pool(config)

with pool.connect() as conn:
    cursor = conn.cursor()
    cursor.execute("SELECT 42 AS answer")
    row = cursor.fetchone()
    print(row)  # (42,)

pool.dispose()
pool._adbc_source.close()
```

---

**`docs/src/guides/pool-lifecycle.md`** — Pool Lifecycle (DOCS-04):

Cover:
1. What create_pool returns and what it holds internally (source connection + QueuePool)
2. Checkout and return pattern (`with pool.connect() as conn`)
3. How to dispose: `pool.dispose()` then `pool._adbc_source.close()` — explain why both are needed (pool.dispose() drains connections, _adbc_source.close() releases the underlying ADBC source connection)
4. Fixture teardown pattern for pytest tests:
   ```python
   import pytest
   from adbc_poolhouse import DuckDBConfig, create_pool

   @pytest.fixture(scope="session")
   def pool():
       p = create_pool(DuckDBConfig(database="/tmp/test.db"))
       yield p
       p.dispose()
       p._adbc_source.close()
   ```
5. Common mistakes section:
   - Not closing _adbc_source after dispose (resource leak)
   - Using `database=":memory:"` with pool_size > 1 (raises ValueError — each connection gets an isolated empty DB)
   - Holding connections outside `with` block (not returned to pool)

---

**`docs/src/guides/consumer-patterns.md`** — Consumer Patterns (DOCS-03):

Cover two complete examples per CONTEXT.md:

**Example A — SQLAlchemy ORM direct config pattern:**
Show how to wire a DuckDB or Snowflake pool into a FastAPI application using SQLAlchemy ORM. Use a session factory pattern where the pool is created at startup and disposed at shutdown:

```python
from contextlib import asynccontextmanager
from fastapi import FastAPI
from sqlalchemy import create_engine
from adbc_poolhouse import DuckDBConfig, create_pool

pool = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    global pool
    pool = create_pool(DuckDBConfig(database="/data/warehouse.db"))
    yield
    pool.dispose()
    pool._adbc_source.close()

app = FastAPI(lifespan=lifespan)
```

Note that `adbc_poolhouse` returns a SQLAlchemy `QueuePool` — to use it with SQLAlchemy ORM, pass `creator=pool.connect` to `create_engine`. Keep the example focused on the pool wiring, not full ORM setup.

**Example B — dbt-open-sl profiles.yml shim pattern:**
Show how to read a dbt `profiles.yml` and construct the matching adbc-poolhouse config. This pattern is for consumers who already have dbt profiles configured and want to reuse the same credentials:

```python
import yaml
from pathlib import Path
from adbc_poolhouse import SnowflakeConfig, create_pool

# Load dbt profile
profiles_path = Path.home() / ".dbt" / "profiles.yml"
with profiles_path.open() as f:
    profiles = yaml.safe_load(f)

creds = profiles["my_project"]["outputs"]["dev"]

config = SnowflakeConfig(
    account=creds["account"],
    user=creds["user"],
    password=creds["password"],
    database=creds["database"],
    schema_=creds["schema"],
)
pool = create_pool(config)
```

Note: this requires `pyyaml` (not bundled with adbc-poolhouse). For production use, prefer loading from environment variables directly using SnowflakeConfig's env_prefix support.

---

**`docs/src/guides/configuration.md`** — Configuration Reference:

Cover:
1. How env_prefix works: each config class reads its fields from environment variables with a warehouse-specific prefix (e.g. `SNOWFLAKE_ACCOUNT` → `SnowflakeConfig.account`)
2. Table of all config classes and their env_prefix values:
   | Config class | env_prefix |
   |---|---|
   | DuckDBConfig | DUCKDB_ |
   | SnowflakeConfig | SNOWFLAKE_ |
   | BigQueryConfig | BIGQUERY_ |
   | PostgreSQLConfig | POSTGRESQL_ |
   | FlightSQLConfig | FLIGHTSQL_ |
   | DatabricksConfig | DATABRICKS_ |
   | RedshiftConfig | REDSHIFT_ |
   | TrinoConfig | TRINO_ |
   | MSSQLConfig | MSSQL_ |
3. Pool tuning fields (pool_size, max_overflow, timeout, recycle): all inherited from BaseWarehouseConfig; also loaded from env vars using the warehouse prefix
4. SecretStr fields: values are masked in repr; access with `.get_secret_value()`
5. Short note on Foundry-distributed backends (Databricks, Redshift, Trino, MSSQL): not available on PyPI; must be installed from Foundry

---

**`docs/src/guides/snowflake.md`** — Snowflake Guide:

Cover:
1. Supported auth methods: password, JWT private key (file path or PEM), OAuth, external browser
2. Private key auth — show both variants:
   ```python
   # From file path
   SnowflakeConfig(account="myorg-myaccount", user="me", private_key_path=Path("/keys/rsa.p8"))

   # From PEM content (as SecretStr)
   from pydantic import SecretStr
   SnowflakeConfig(account="myorg-myaccount", user="me", private_key_pem=SecretStr("-----BEGIN..."))
   ```
3. Note: `private_key_path` and `private_key_pem` are mutually exclusive — providing both raises `ConfigurationError`
4. Snapshot testing for CI: link to CONTRIBUTING.md for the snapshot recording workflow (credentials required locally, snapshots committed for CI replay)
5. install: `pip install adbc-poolhouse[snowflake]`

---

**`docs/src/changelog.md`** — Changelog page:

Simple placeholder that links to GitHub Releases. Updated at release time by the release workflow:

```markdown
# Changelog

See [GitHub Releases](https://github.com/anentropic/adbc-poolhouse/releases) for the full changelog.

<!-- Content below is generated by git-cliff at release time -->
```

Apply humanizer pass to all prose in index.md, pool-lifecycle.md, consumer-patterns.md, configuration.md, and snowflake.md. The changelog.md placeholder is too short for a pass.
  </action>
  <verify>
    <automated>ls /Users/paul/Documents/Dev/Personal/adbc-poolhouse/docs/src/guides/ && ls /Users/paul/Documents/Dev/Personal/adbc-poolhouse/docs/src/guides/pool-lifecycle.md /Users/paul/Documents/Dev/Personal/adbc-poolhouse/docs/src/guides/consumer-patterns.md /Users/paul/Documents/Dev/Personal/adbc-poolhouse/docs/src/guides/configuration.md /Users/paul/Documents/Dev/Personal/adbc-poolhouse/docs/src/guides/snowflake.md /Users/paul/Documents/Dev/Personal/adbc-poolhouse/docs/src/changelog.md</automated>
  </verify>
  <done>All six files exist: docs/src/index.md (updated), docs/src/guides/pool-lifecycle.md, docs/src/guides/consumer-patterns.md, docs/src/guides/configuration.md, docs/src/guides/snowflake.md, docs/src/changelog.md</done>
</task>

<task type="auto">
  <name>Task 2: Restructure mkdocs.yml nav and verify build</name>
  <files>mkdocs.yml</files>
  <action>
Update the `nav:` section of `mkdocs.yml` from the current 3-item flat structure to the required 4-section hierarchy. The rest of mkdocs.yml (theme, plugins, markdown_extensions) must remain unchanged.

Replace current nav:
```yaml
nav:
  - Home: index.md
  - API Reference: reference/
  - Changelog: changelog.md
```

With required nav:
```yaml
nav:
  - Getting Started: index.md
  - Guides:
    - Pool Lifecycle: guides/pool-lifecycle.md
    - Consumer Patterns: guides/consumer-patterns.md
    - Configuration Reference: guides/configuration.md
    - Snowflake Guide: guides/snowflake.md
  - API Reference: reference/
  - Changelog: changelog.md
```

After updating mkdocs.yml, run the build:
```bash
cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && uv run mkdocs build --strict
```

The build must pass. If it fails:
- Missing guide files: check Task 1 completed successfully
- Missing API reference: `gen_ref_pages.py` auto-generates — ensure `docs/scripts/gen_ref_pages.py` is unmodified
- Docstring syntax errors in source: fix the offending file
- `changelog.md` not found: confirm Task 1 created it

Do NOT modify `docs/scripts/gen_ref_pages.py` — it correctly skips `_`-prefixed private modules and generates the reference automatically.
  </action>
  <verify>
    <automated>cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse && uv run mkdocs build --strict 2>&1 | tail -5</automated>
  </verify>
  <done>`uv run mkdocs build --strict` exits 0; mkdocs.yml nav has four top-level sections: Getting Started, Guides, API Reference, Changelog; Guides section has four entries</done>
</task>

</tasks>

<verification>
```bash
cd /Users/paul/Documents/Dev/Personal/adbc-poolhouse

# Verify nav structure
grep -A 10 "^nav:" mkdocs.yml

# Verify guide files exist
ls docs/src/guides/

# Verify build passes
uv run mkdocs build --strict && echo "BUILD OK"

# Verify quickstart has DuckDB code example
grep -c "create_pool" docs/src/index.md
```
</verification>

<success_criteria>
- `uv run mkdocs build --strict` exits 0 with no errors
- mkdocs.yml nav has four sections: Getting Started / Guides / API Reference / Changelog
- Guides section has four pages: pool-lifecycle, consumer-patterns, configuration, snowflake
- docs/src/index.md contains a full working DuckDB `create_pool` code example
- docs/src/guides/consumer-patterns.md shows both the ORM direct config pattern and the dbt-open-sl shim pattern
- docs/src/guides/pool-lifecycle.md covers dispose(), _adbc_source.close(), and pytest fixture pattern
- docs/src/changelog.md exists with link to GitHub Releases
</success_criteria>

<output>
After completion, create `.planning/phases/07-documentation-and-pypi-publication/07-03-SUMMARY.md`
</output>
